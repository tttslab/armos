**Actor-critic algorithm based algorithm**

The policy function (actor) outputs Gaussian distributions and the articulatory
movements are estimated with Maximum Likelihood Parameter Generation (MLGP).

We use VocalTractLab 2.1 as the articulatory synthesizer.
http://www.vocaltractlab.de/

These files are from VocalTractLab 2.1:
-JD2.speaker: Adult male speaker file.
-VocalTractLabApi.so: VTL library

The following codes are written based on the example code
TractSeqToWave_Example in VocalTractLab
-TractSeqToWave_Func.py: For training
-TractSeqToWave_File.py: For evaluation

exp: Trained model is saved in this directory.
     "p" denotes actor (policy) and "q" denotes critic (Q func).
log: Log file is saved
datalist
-training_list.txt: List of training data path. Relative path from feat_dir.
-testing_list.txt: List of test data path. 
-validation_list.txt: List of validation data path. 

testdata
(For additional experiments to evaluate estimation errors of tract parameters,
we generate waveform samples from known tract parameters)
-testdata.npy: Correct tract parameters
-num.wav: Test sound

config.ini
-in_size: Dimension of acoustic features
-out_size: The number of articulatory parameters
-batch_size: Batch size for training
-num_sample: Do not use. If you set the output of actor to a distribution, use this parameter.
-num_paral: Parallelize synthesis step.
	    Set a divisor of batch_size.(because of my(shibata) laziness)
-sampling_rate: Sampling rate of original sounds.
-frameRate_Hz: Frame rate of articulatory.
	       For now fixed to 100 in order to correspond to acoustic feature.
-audio_segment: The number of acoustic feature's frames for training.
		This number's frames are randomly extracted from whole utterance, and use for training.
-wave_dir: Directory of original sounds data.
-feat_dir: Extracted acoustic features are saved in this directory.
-feat_type: You can select MFCC, FBANK or log-FBANK.
-hidden_size: The number of units of LSTM.
-num_layers: The number of stacked BLSTM.
-delta: Necessary for Parameter space noise. Refer to the original paper.
-sigma_init: Initial value of gaussian distribution's standard deviation.
-adjust_step: Adjust sigma per this value.
-learning_rate: Learning rate for actor (SGD) and critic (Adam).

eval.py: Calculate RMSE of articulatory using test data.
	 The result is saved in log/eval.csv.
	 Each column corresponds to each tract parameters. About the order, refer to a speaker file.
	 Note that 9th parameter (WC) is meaningless.
eval.sh: Evaluation script per 1000 iterations.
models.py: Define actor and critic.
pretrain.py: Make the output of actor close to 0.5.
	     Log file is saved in log/pretrain.log.
	     Trained model is saved in exp/pretrain.model.
train.py: Training script. The log is saved in log/train.log.
	  I recommend below command to run this:
	    	      nohup python train.py 1>/dev/null 2>log/err.log
validation.py: For varidation. The log is saved in log/valid.log.
               Usage:
                python validation.py iteration validation batch_size num_cpu
                ex) python validation.py 10000 validation 100 10 1>/dev/null
test.py: For test. The log is saved in log/test.log.
                python test.py iteration testing batch_size num_cpu
                ex) python test.py 10000 testing 100 10 1>/dev/null
utils.py: Some functions are defined.
generate_sound.py: Estimate and synthesize a sound.
		   The head of synthesized sound has extra 50ms sound and its tail has extra 50+alpha ms sound.
		   The output is synthesized.wav.
		   Example command is below:
		      python generate_sound.py path/to/hoge.wav exp/p1000.model
		      sox synthesized.wav output.wav trim 0.05 1.6
